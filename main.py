# -*- coding: utf-8 -*-
"""20BCE7218_PROJECT.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1b9mQVgFmNfvsMLG0-mFhb438AY79ceGI
"""

import pandas as pd
import matplotlib.pyplot as plt

# Machine Learnig
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier, AdaBoostClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.model_selection import cross_val_score
from sklearn.naive_bayes import GaussianNB, MultinomialNB
from sklearn.svm import LinearSVC

from google.colab import drive
drive.mount('/content/drive')

train = pd.read_csv('/content/drive/My Drive/Colab Notebooks/train.csv')

print(train.shape)
print('-'*40)
print(train.info())
print('-'*50)
print(train.describe())
print('-'*50)
print(train.describe(include=['O']))
print('-'*50)
print(train.head(5))

(train.isnull().sum().sort_values(ascending=False)*100)/train.shape[0]

train.drop(['Cabin','Ticket','Name'], axis=1 ,inplace=True)

train.Age = train.Age.fillna(train.Age.median())

train = train.apply(lambda x:x.fillna(x.value_counts().index[0]))

train['Sex'] = train['Sex'].map( {'female': 1, 'male': 0} ).astype(int)
train['Embarked'] = train['Embarked'].map( {'Q': 0, 'C': 1,'S':2} ).astype(int)
train.head()

X = train.drop('Survived',axis=1)
y = train['Survived']

"""LOGISTIC REGRESSION

"""

lr = LogisticRegression(max_iter=500)
scores_lr = cross_val_score(lr, X, y, cv = 8)
print(scores_lr.mean(), scores_lr.std())

"""Naive Bayes"""

nb = GaussianNB()
scores_nb = cross_val_score(nb, X, y, cv = 8)
print(scores_nb.mean(), scores_nb.std())

"""KNN"""

knn = KNeighborsClassifier()
scores_knn = cross_val_score(knn, X, y, cv = 8)
print(scores_knn.mean(), scores_knn.std())

"""RANDOM FOREST"""

rand = RandomForestClassifier(n_estimators=300, max_depth=10)
scores_rand = cross_val_score(rand, X, y, cv = 6)
print(scores_rand.mean(), scores_rand.std())

"""DECISION TREE"""

tr = DecisionTreeClassifier()
scores_tr = cross_val_score(tr, X, y, cv = 6)
print(scores_tr.mean(), scores_tr.std())

"""SVM"""

sv = LinearSVC(C=0.0001)
scores_sv = cross_val_score(sv, X, y, cv = 8)
print(scores_sv.mean(), scores_sv.std())

"""VOTING"""

evc=VotingClassifier(estimators=[('nb',nb),('lr',lr),('rf',rand),('grd',grd)],voting='hard')
scores_evc = cross_val_score(evc, X, y, cv = 8)
print(scores_evc.mean(), scores_evc.std())

names = ['LogisticRegression' , 'Random Forest Classifier','Naive Bayes', 'SVM',
         'Decision Tree',  'Voting Classification', 'KNN']
acc = [scores_lr.mean(),scores_rand.mean(),scores_nb.mean(),scores_sv.mean(),
      scores_tr.mean(), scores_grd.mean(),  scores_knn.mean()]

plt.figure(figsize=(10,8))
graph = plt.barh(names,acc)
plt.xlabel('Accuracy')
plt.ylabel('Models')
graph[0].set_color('red')
graph[1].set_color('blue')
graph[3].set_color('green')
graph[4].set_color('yellow')
graph[5].set_color('maroon')
graph[6].set_color('grey')